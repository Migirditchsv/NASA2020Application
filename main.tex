\documentclass[12pt]{article}

\usepackage
[
        %a4paper,% other options: a3paper, a5paper, etc
         left=1.00in,
         right=1.00in,
         top=1.00in,
         bottom=1.00in,
]
{geometry}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{paralist}
\usepackage{graphicx}
\usepackage{epsfig} %For pictures: screened artwork should be set up with an 85 or 100 line screen
\usepackage[utf8]{inputenc}
\usepackage{bm}
\usepackage{rotating} 
\usepackage{enumitem} 
\usepackage{url}
\usepackage{xspace} 
\usepackage{wrapfig}
\usepackage{verbatim} 
\usepackage{changepage}   % for the adjustwidth environment
\usepackage{multirow}
\usepackage{array}
\usepackage{graphics}
\usepackage[tight]{subfigure}
%\usepackage{float}
\usepackage{floatrow} % not compatible with float
\usepackage{times} 
\usepackage{pifont}
\usepackage{soul}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage{biblatex}

\addbibresource{citations.bib} %Imports bibliography file

\title{\textbf{DELETE THIS WHOLE PAGE. COVER PAGE GENERATED BY NSPIRES}\linebreak Multi-Scale Markov Decision Processes for Planning Under Uncertainty}
\author{Sam Migirditch}
\date{February 21, 2020}

\begin{document}

\maketitle

\newpage
\section{Project Summary [DELETE SECTION add to NSPIRES online form]}

Trajectory planning for robotics is a well studied problem but finding safe paths through risky and uncertain environments remains challenging[***]. Many proposed solutions have found moderate success but all have their limitations[***]. Markov Decision Processes (MDPs) can theoretically find optimal solutions, but in practice are limited by their costly dependence on the size of their state and action space. We propose a  Multi-Scale MDP (MSMDP) method that aims to minimize this action and state space limitation while also providing a degree of algorithmic modality that reduces the need for situation specific policy functions and delivering planning that more efficiently handles disturbances from the environment. This work aims to deploy the MDMDP method in simulation as well as a physical platform to illustrate the real world practicality. 

\newpage
\section{Impact Statement [2 PAGES]}

\subsection{The Research Gap}

Planning is at the core of robotics and planning under uncertainty in robotics has a long history with many fronts. Over the last two decades probabilistic robotics has become a leading philosophy for managing uncertainty \cite{thrun_probabilistic_2005}. MDP based approaches fit naturally into the probabilistic approach to planning but their application is often limited by their polynomial time dependence on the size of the state and actions spaces. Most non-trivial planning tasks must wrestle with the challenge of efficiently exploring large action or state spaces and some interesting work has emerged using hierarchical modeling to beat the trade off of accuracy versus speed using situation specific simulations of various levels of resolution \cite{fisac_hierarchical_2019}. The limited research that has attempted to leverage the benefits of hierarchical or multi-scale modeling in MDP solvers show promise in performance improvements but are limited to relatively simple 2D environments with known obstacles \cite{bakker_hierarchical_2005} or constrain the finer scale MDPs using heuristics that are application specific and do not incorporate information from other scales \cite{ferguson_focussed_2004}. We are unaware of work combining information between MDP policies, across scales in uncertain environments.

\subsection{Indiana University's Capacity and NASA Partnership Impact}
\textit{Discuss the impact of NASA partnership on the institution’s capacity and
capabilities}
Indiana University Bloomington has a rich ecology of researchers studying adjacent issues from multiple perspectives. The Intelligent Systems Engineering department ***

\subsection{Commercialization and Technology Transfer}

\subsection{Scientific Impact}
\textit{Consider the scientific impact of the proposed effort on NASA and the larger
scientific society, with a focus on the candidate’s specific field of study.}

\subsection{Benefits of NASA Participation}
\textit{The statement shall have specific information on the need for NASA participation in
the research due to NASA-unique facilities, personnel, and institutional knowledge.
To expand on the impact statement, the proposal shall include a description of how
the candidate’s prior research experience will enhance the candidate’s current
NASA research, to include a brief description on the Center Based Research
Experience}

\newpage
\section{ ***PLACEHOLDER*** Lantao CV }

\newpage
\section{Project Description[6 pages]}

\subsection{Problem Statement}
\subsection{Background}
\subsection{General Methodology}
Previous works have used different approaches to limit both value updates and policy updates to a promising subset of promising states. These results depend on the assumption that dead reckoning is good, that there is little difference between the selected action and the performed action, and that perturbations will not knock the vehicle out of the promising states into a region where the value and policy functions are not optimized to perform.
\newline
We define planning as the process of finding an optimal policy in a discrete-time Markov Decision Process(MDP) with continuous states and two sets of actions, $\pi_{macro}(s_k)$ and $\pi_{micro}(s_k,a_{macro})$ such that $a_{macro} = \pi_{macro}(s_{trajectory})$ where $s_{trajectory}$ is an element is a set of actions sampled from $\pi_{macro}$ applied to some actively sensed reward field . We denote the state and action at time step $k$ as $\mathbf{s}_k \in \mathbb{R}^D$ and $\mathbf{a}_k \in \mathbb{R}^M$, respectively.

The  traditional MDP is run returning a macroscopic policy that defines checkpoint positions of a given step size from an initial state towards a goal state. One or more trajectories are sampled from the starting state to some intermediary state along n steps of the macroscopic policy. The macroscopic trajectories are pause at an intermediate point when the variance of their state distribution reaches some preset ratio of the macroscopic step size. For the single macroscopic trajectory case, the vehicle may now immediately start out with a microscopic policy that returns kinematic instructions (linear and angular velocity) that were derived from a reward function that optimizes for proximity to the next point in the  macroscopic trajectory, alignment of the velocity vector to some (potentially smoothed) curve along the macroscopic trajectory or some combination of these as well as any defined reward field. That is to say the microscopic policy is defined in terms of the macroscopic one $\pi_{micro}(s_t,a_{next}) \textrm{ s.t. } a_{next} \in \{\textrm{macroscopic trajectory}\}$. When the vehicle reaches the final intermediate point, a new macroscopic trajectory, or set of trajectories are developed and the process is repeated until a goal is reached.

This separation of scales has several implicit benefits, firstly, the microscopic policy function can be largely evolved for a generic situation offline and any disturbance function $\phi$ can be learned or and applied here. Because the microscopic policy is defined in terms of the local macroscopic policy it remains valid between different macroscopic policies. $\pi_{micro}$ is characterized by the disturbance function $\phi$ and the physics of the type of environment. Second, in situations with a time changing environment ( for example, an aquatic drone in a current ) and intelligent responses are needed rapidly, potentially faster than a new $\pi_{macro}$ can be solved for, a generalized microscopic policy can be viewed as a controller that can be fed a pre-existing fall back policy $\pi_{micro}(s_t,a_{fallback})$. Continuing the autonomous boat example, in the event that the boat becomes trapped in a current unseen by the macroscopic model, a reasonable fallback policy might direct the microscopic policy to directs it to travel perpendicular to the perceived current. Finally, the multi-scale approach may help reduce the impact of indistinguishable maxima. In macroscopic regions of the environment where the divergence of the macroscopic policy is high, meaning that different nearby diverging trajectories return similar rewards, using rollouts over these trajectories with $\pi_{micro}$ may reveal significant differences in the reward of trajectories that were missed at coarser scales.
\subsection{Timeline}
\subsection{Explanation of Novel Techniques}
\subsection{Expected Results and Applications}
\subsection{Citations}
\printbibliography

\newpage
\section{Program Degree Schedule }
\textit{This section shall be titled “Degree Program
Schedule” and shall not exceed two pages in length. The schedule shall state the
proposed start and completion dates, expected course schedule, as well as anticipated
milestones of the institution’s candidate’s degree program, such as Candidacy Exams.
There is no standard format for this section}

\newpage
\section{ ***PLACEHOLDER*** SAM CV }

\newpage
\section{Personal Statement}
\textbf{The Personal Statement shall respond to the
prompt: How do you envision graduate school preparing you for a career that allows you
to contribute to expanding scientific understanding and its application to NASA’s
mission? Describe your personal, educational and/or professional experiences that inspire and
motivate your decision to pursue advanced studies in science, technology, engineering
or mathematics (STEM) and in NASA-related research. Include specific examples of any
research and/or professional activities in which you have participated. Present a concise
description of the activities, highlight the results and discuss how these activities have
prepared you to seek a graduate degree. Specify your role in the activity including the
extent to which you worked independently and/or as part of a team. Describe the
contributions of your activity to advancing knowledge in STEM fields, as well as the
potential impacts in NASA Missions.}

\newpage
\section{ ***PLACEHOLDER*** TRANSCRIPTS }

\newpage
\section{ ***PLACEHOLDER*** LETTERS OF REC }

\newpage
\section{ ***PLACEHOLDER*** LETTER OF SUPPORT }

\end{document}
